
# Adapted by: Philip Dishuck
# 2022-09-22
# email: pdx@uw.edu

# original author: Peter Edge
# 12/19/2016
# email: pedge@eng.ucsd.edu

# this is a snakemake Snakefile, written using snakemake 3.5.5

localrules: all

################################################################################
# USER CONFIG
# change this list to limit the chromosomes analyzed
chroms = ['chr{}'.format(x) for x in range(1,23)]+['chrX'] #,'chrY']
# edit these to point to the correct paths for binaries / jars
# or just the program name if you have them in your PATH
REFERENCE    = "/net/eichler/vol26/eee_shared/assemblies/CHM13/T2T/v1.1/chm13.v1.1.fasta" 
LONGREAD_BAM = '../HG02723/align_ont/HG02723_HiFi_to_T2T/alignments/ONT/minimap2/all_ONT.bam'
HIC_FASTQ    = 'data/hic_{mate}.fastq' # path must end in _{mate}.fastq, with two files ending in _1.fastq _2.fastq both present
VCF_DIR      = 'by_chrom'            # vcf files should be in this directory and formatted as chr1.vcf, chr2.vcf...
HAPCUT2      = 'hapcut2'
EXTRACTHAIRS = 'extractHAIRS'
BWA          = 'BWA'      # 0.7.12-r1044
SAMTOOLS     = 'samtools' # samtools 1-2, htslib 1.21
PICARD       = '/net/gs/vol3/software/modules-sw/picard/2.14.0/Linux/CentOS7/x86_64/picard.jar'   # picard version 2.8
BAMTOOLS     = 'bamtools' # version 2.4
################################################################################

import HiC_repair

rule all:
    input:
        expand('output/{chrom}.hap',chrom=chroms),
        expand('output/{chrom}.hap.tsv',chrom=chroms),
        expand('output/longread/longread.REF_{chrom}.haplotag.bam', chrom=chroms),

rule haptag_tsv:
  input: bam = 'output/longread/longread.REF_{chrom}.haplotag.bam',
  output: tsv = 'output/{chrom}.hap.tsv',
  shell: "bin/haptag {input.bam} {output.tsv}"

#Haplotag reads
rule haplotag:
    params: job_name = '{chrom}.whatshap',
    input:  frag_file = 'data/hic_longread/{chrom}',
            vcf_file  = '%s/{chrom}.vcf' % VCF_DIR,
            hap = 'output/{chrom}.hap',
            bam = 'data/longread_separated/longread.REF_{chrom}.bam'
    output: hapcut = 'output/{chrom}.hap.cut',
            vcf = 'output/{chrom}.vcf',
            phased_vcf = 'output/{chrom}.phased.vcf',
            phased_vcf_gz = 'output/{chrom}.phased.vcf.gz',
            bam = 'output/longread/longread.REF_{chrom}.haplotag.bam'
    shell:
        '''
samtools index -@ 16 {input.bam}
cut -d$'\\t' -f1-11 {input.hap} > {output.hapcut}
whatshap hapcut2vcf {input.vcf_file} {output.hapcut} -o {output.vcf}
whatshap phase --reference {REFERENCE} {input.vcf_file} {output.vcf} {input.bam} -o {output.phased_vcf}
bgzip -c {output.phased_vcf} > {output.phased_vcf_gz}
tabix {output.phased_vcf_gz}
whatshap haplotag --ignore-read-groups  --reference {REFERENCE} {output.phased_vcf_gz} {input.bam} -o {output.bam}
        '''

# run HapCUT2 to assemble haplotypes from combined Hi-C + longread haplotype fragments
rule run_hapcut2_hic_longread:
    params: job_name = '{chrom}.hapcut2_hic_longread',
    input:  frag_file = 'data/hic_longread/{chrom}',
            vcf_file  = '%s/{chrom}.vcf' % VCF_DIR
    output: hap = 'output/{chrom}.hap',
            model_file = 'output/{chrom}.htrans_model'
    shell:
        '''
        {HAPCUT2} --fragments {input.frag_file} --vcf {input.vcf_file} --output {output.hap} --hic 1 --htrans_data_outfile {output.model_file}
        '''

# then concatenate Hi-C fragment file and longread fragment file
rule concatenate_hic_longread:
    params: job_name = 'concatenate_hic_longread'
    input:  hic = expand('data/hic/{chrom}',chrom=chroms),
            longread = expand('data/longread/{chrom}',chrom=chroms)
    output: hic_longread = expand('data/hic_longread/{chrom}',chrom=chroms)
    run:
        for hic, longread, hic_longread in zip(input.hic, input.longread, output.hic_longread):
            shell('cat {hic} {longread} > {hic_longread}')

# convert Hi-C bam files to haplotype fragment files
rule longread_extract_hairs:
    params: job_name    = 'longread_extracthairs',
    input:  expand('data/longread_separated/longread.REF_{chrom}.bam',chrom=chroms)
    output: expand('data/longread/{chrom}',chrom=chroms)
    run:
        for chrom,bam,frag in zip(chroms,input,output):
            shell('{EXTRACTHAIRS} --ont 1 --new_format 1 --ref {REFERENCE} --bam {bam} --VCF {VCF_DIR}/{chrom}.vcf > {frag}')

# convert Hi-C bam files to haplotype fragment files
rule hic_extract_hairs:
    params: job_name    = 'hic_extracthairs',
    input:  expand('data/hic_separated/hic.REF_{chrom}.fix.bam',chrom=chroms)
    output: expand('data/hic/{chrom}',chrom=chroms)
    run:
        for chrom,bam,frag in zip(chroms,input,output):
            shell('{EXTRACTHAIRS} --hic 1 --ref {REFERENCE} --bam {bam} --VCF {VCF_DIR}/{chrom}.vcf > {frag}')

# split bam files by chromosome
rule split_bams:
    params: job_name = '{dataset}_bamsplit',
            stub     = 'data/{dataset}_separated/{dataset}',
    input:  bam = 'data/{dataset}.bam'
    output: expand('data/{{dataset}}_separated/{{dataset}}.REF_{chrom}.bam',chrom=chroms)
    shell:
        '{BAMTOOLS} split -in {input} -reference -stub {params.stub}'

# index reference genome
rule index_genome:
    params: job_name = 'index_reference'
    input:  REFERENCE
    output: REFERENCE+'.bwt'
    shell:
        '{BWA} index {REFERENCE}'

# index bamfile
rule index_bam:
    params: job_name = 'index_bam{x}'
    input:  bam = '{x}.bam'
    output: bai = '{x}.bam.bai'
    shell:  '{SAMTOOLS} index {input.bam} {output.bai}'
